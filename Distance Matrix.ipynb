{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from geopy import distance\n",
    "pd.set_option('display.max_columns', None)\n",
    "# useful functions and classes\n",
    "\n",
    "# This class stores the latitude and longitude of a sample, and indicates \n",
    "# if this location has the desired variable we are estimating\n",
    "class Location:\n",
    "    def __init__(self,latitude,longitude,hasv,ID,value):\n",
    "        self.ID = ID\n",
    "        self.latitude = latitude\n",
    "        self.longitude = longitude\n",
    "        self.hasv = hasv\n",
    "        self.value = value\n",
    "        \n",
    "    def __str__(self):\n",
    "        return str(self.ID)\n",
    "\n",
    "# Calculates the distance between 2 samples in km\n",
    "def getdist(S1,S2):\n",
    "    # radius of earth in km\n",
    "    coords_1 = (S1.latitude, S1.longitude)\n",
    "    coords_2 = (S2.latitude, S2.longitude)\n",
    "    dist = distance.distance(coords_1, coords_2).km\n",
    "    return dist\n",
    "\n",
    "# filters out data if a point is missing in one of the colunns\n",
    "def filterblanks(columns,data,blank):\n",
    "    # if blank is true, rows with blanks in these columns\n",
    "    # if blank is false, remove rows with non blanks or non zeros in these columns\n",
    "    for c in columns:\n",
    "        if blank:\n",
    "            data = data[data[c].notnull()]\n",
    "        else:\n",
    "            data = data[data[c].isnull() | (data[c]==0)]\n",
    "    return data\n",
    "\n",
    "# PRE: all locations in the dataframe are\n",
    "# unique\n",
    "def DistanceMatrix(dataframe,variable):\n",
    "    # the list of location objects\n",
    "    locations = []\n",
    "    # the list of indexes where the the row is located in the dataframe\n",
    "    #indexes = []\n",
    "    for index,row in dataframe.iterrows():\n",
    "        # make a location object on this row\n",
    "        if pd.isnull(row[variable]):\n",
    "            hasv = False\n",
    "        else:\n",
    "            hasv = True\n",
    "        locations.append(Location(row[\"LATITUDE\"],row[\"LONGITUDE\"],hasv,row[\"LOCATCD\"],row[variable]))\n",
    "        #indexes.append(index)\n",
    "        \n",
    "    matrix = pd.DataFrame(0,index=locations,columns=locations)\n",
    "    for ci,column in enumerate(locations):\n",
    "        for ri,row in enumerate(locations):\n",
    "            if ri>ci:\n",
    "                # compute distance between column and row\n",
    "                dist = getdist(row,column)\n",
    "            elif ci>ri:\n",
    "                dist = matrix.iloc[ci,ri]\n",
    "            # put this distance in the dataframe\n",
    "            else:\n",
    "                continue\n",
    "            matrix.iloc[ri,ci] = dist\n",
    "    return matrix\n",
    "\n",
    "def changeVar(DM,data,variable):\n",
    "    locations = DM.index\n",
    "    # loop through each location\n",
    "    for loc in location:\n",
    "        ID = loc.ID\n",
    "        row = data[data[\"LOCATCD\"]==ID]\n",
    "        if pd.isnull(row[variable]):\n",
    "            loc.hasv = False\n",
    "            loc.value = None\n",
    "        else:\n",
    "            loc.hasv = True\n",
    "            loc.value = row[variable]\n",
    "            \n",
    "    DM.index = locations\n",
    "    DM.columns = locations\n",
    "        \n",
    "def getclosest(numclosest,distancematrix,location):\n",
    "    # Make a set of the closest locations that contain variable\n",
    "    closest = {}\n",
    "    column = distancematrix.loc[:,location].copy()\n",
    "    print(type(distancematrix.index[0]))\n",
    "    # Filter the locations that dont have the desired variable\n",
    "    doesnthavev = []\n",
    "    for i in range(len(column)-1):\n",
    "        if not column.index[i].hasv:\n",
    "            doesnthavev.append(column.index[i])\n",
    "    column.drop(doesnthavev,inplace = True)\n",
    "    \n",
    "    #print(type(column))\n",
    "    column.sort_values(inplace = True)\n",
    "    #print(column.iloc[0])\n",
    "\n",
    "    column.iloc[0] = 0\n",
    "    #print(column.iloc[0])\n",
    "    if column.iloc[0]==0:\n",
    "        column = column.iloc[1:]\n",
    "    return column.iloc[0:numclosest]\n",
    "\n",
    "# Key: Location Code\n",
    "# Value: List of tuples (locatcd,distance,value)\n",
    "def makeDict(data,variable,numclosest=2):\n",
    "    D = DistanceMatrix(data,variable)\n",
    "    # Loop through each location without a value for variable\n",
    "    closestDict = {}\n",
    "    for loc in D.columns:\n",
    "        if not loc.hasv:\n",
    "            # Get the closest locations to loc\n",
    "            closest = getclosest(numclosest,D,loc)\n",
    "            # The list of tuples that contain location id, the distance, and the value for variable\n",
    "            tuples = []\n",
    "            for i,dist in enumerate(closest):\n",
    "                ID = closest.index[i].ID\n",
    "                val = closest.index[i].value\n",
    "                tuples.append((ID,dist,val))\n",
    "            closestDict[loc.ID] = tuples\n",
    "    return closestDict\n",
    "\n",
    "def predict(tuples,numclosest = 2):\n",
    "    loc2 = tuples[0]\n",
    "    loc3 = tuples[1]\n",
    "    d12 = loc2[1]\n",
    "    val2 = loc2[2]\n",
    "    d13 = loc3[1]\n",
    "    val3 = loc3[2]\n",
    "    \n",
    "    c2 = d12/(d12+d13)\n",
    "    c3 = d13/(d12+d13)\n",
    "    \n",
    "    predicted = c2*val2+c3*val3\n",
    "    \n",
    "    return predicted\n",
    "\n",
    "# NEEDS WORK\n",
    "def addpredictions(df,variables,numclosest):\n",
    "    # make prediction and insert for each variable\n",
    "    first = True\n",
    "    for var in variables:\n",
    "        if first:\n",
    "            DM = DistanceMatrix(df,var)\n",
    "        else:\n",
    "            changeVar(DM,df,var)\n",
    "            \n",
    "        for loc in DM.columns:\n",
    "            if not loc.hasv:\n",
    "                # Get the closest locations to loc\n",
    "                closest = getclosest(numclosest,DM,loc)\n",
    "                # The list of tuples that contain location id, the distance, and the value for variable\n",
    "                tuples = []\n",
    "                for i,dist in enumerate(closest):\n",
    "                    ID = closest.index[i].ID\n",
    "                    val = closest.index[i].value\n",
    "                    tuples.append((ID,dist,val))\n",
    "                closestDict[loc.ID] = tuples\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open( \"water_data_coords.p\", \"rb\" ))\n",
    "path = r\"C:\\Users\\cashe\\OneDrive\\Desktop\\Data Science\\Mississippi River analysis\\Krouth_water_and_veg_data_w_latlong\\ltrm_water_data_lat_long.csv\"\n",
    "doug_data = pd.read_csv(path,low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering columns:  (106052, 29)\n",
      "Now filtering sampling design\n",
      "After filtering sampling design:  (106052, 29)\n",
      "Now filtering Pool 13\n",
      "After filtering Pool 13:  (17991, 29)\n",
      "Now adding a year column\n",
      "(17991, 30)\n",
      "Adding a timecode column\n",
      "(17991, 31)\n",
      "Filtering by year 1997\n",
      "(613, 31)\n",
      "Filtering by summer\n",
      "(151, 31)\n",
      "Filtering out points with blank entries in at least one of the columns\n",
      "(64, 31)\n"
     ]
    }
   ],
   "source": [
    "data.drop(data.columns.difference(['TN','TP','TPQF','TNQF','SS','SSQF',\n",
    "                                         'TURB','TURBQF','WDP',\n",
    "                                         'TEMP','TEMPQF','DO','DOQF','COND',\n",
    "                                         'CONDQF','VEL','VELQF','FLDEAST',\n",
    "                                         'FLDNORTH','PROJCD','FLDNUM','DATE',\n",
    "                                  'LOCATCD','STRATUM','CHLcal','SECCHI','SECCHIQF','LATITUDE','LONGITUDE']), 1, inplace=True)\n",
    "print(\"After filtering columns: \",data.shape)\n",
    "print(\"Now filtering sampling design\")\n",
    "data = data[(data.PROJCD == \"M-\")]\n",
    "print(\"After filtering sampling design: \",data.shape)\n",
    "print(\"Now filtering Pool 13\")\n",
    "data = data[(data.FLDNUM == 3)]\n",
    "print(\"After filtering Pool 13: \",data.shape)\n",
    "print(\"Now adding a year column\")\n",
    "data[\"YEAR\"] = pd.DatetimeIndex(data[\"DATE\"]).year\n",
    "print(data.shape)\n",
    "print(\"Adding a timecode column\")\n",
    "data[\"TIME CODE\"] = data[\"LOCATCD\"].astype(str).apply(lambda x: x[3])\n",
    "print(data.shape)\n",
    "print(\"Filtering by year 1997\")\n",
    "data = data[data[\"YEAR\"]==1997]\n",
    "print(data.shape)\n",
    "print(\"Filtering by summer\")\n",
    "data = data[data[\"TIME CODE\"] == '2']\n",
    "print(data.shape)\n",
    "#print(\"Dropping 'bad' data\")\n",
    "#QFcols = ['TPQF','TNQF','SSQF','TURBQF','TEMPQF','DOQF','CONDQF','VELQF','SECCHIQF']\n",
    "#qualdata = filterblanks(QFcols,data,False)\n",
    "#print(qualdata.shape)\n",
    "#print(\"Dropping all blank columns\")\n",
    "#qualdata.drop(['PROJCD','FLDEAST','FLDNORTH','TPQF','TNQF','SSQF','TURBQF','TEMPQF','DOQF',\n",
    "#                                         'CONDQF','VELQF','SECCHIQF'], 1, inplace=True)\n",
    "#print(qualdata.shape)\n",
    "print(\"Filtering out points with blank entries in at least one of the columns\")\n",
    "cols = ['TN','TP','TEMP','DO','TURB','COND','VEL','SS','WDP','CHLcal','SECCHI']\n",
    "#for col in cols:\n",
    "#    print(col,data[col].isna().sum())\n",
    "qualdata_noprediction = filterblanks(cols,data,True)\n",
    "print(qualdata_noprediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 31)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"SECCHIQF\"].isnull()&data[\"TEMPQF\"].isnull()&data[\"DOQF\"].isnull()&data[\"TURBQF\"].isnull()&data[\"CONDQF\"].isnull()\n",
    "    &data[\"VELQF\"].isnull()&data[\"TPQF\"].isnull()&data[\"TNQF\"].isnull()&(data[\"SSQF\"]==0)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(151, 31)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81, 31)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[(data[\"SECCHIQF\"]==0)|(data[\"TEMPQF\"]==0)|(data[\"DOQF\"]==0)|(data[\"TURBQF\"]==0)|(data[\"CONDQF\"]==0)|\n",
    "    (data[\"VELQF\"]==0)|(data[\"TPQF\"]==0)|(data[\"TNQF\"]==0)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n",
      "<class '__main__.Location'>\n"
     ]
    }
   ],
   "source": [
    "DictTN = makeDict(data,\"TN\")\n",
    "DictTP = makeDict(data,\"TP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put in predicted TN\n",
    "data[\"PredictedTN\"] = 0\n",
    "for index,row in data.iterrows():\n",
    "    if pd.isnull(row[\"TN\"]):\n",
    "        data.loc[index,\"PredictedTN\"] = predict(DictTN[row[\"LOCATCD\"]])\n",
    "    else:\n",
    "        data.loc[index,\"PredictedTN\"] = row[\"TN\"]\n",
    "\n",
    "data[\"PredictedTP\"] = 0\n",
    "for index,row in data.iterrows():\n",
    "    if pd.isnull(row[\"TP\"]):\n",
    "        data.loc[index,\"PredictedTP\"] = predict(DictTP[row[\"LOCATCD\"]])\n",
    "    else:\n",
    "        data.loc[index,\"PredictedTP\"] = row[\"TP\"]      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(151, 33)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering out points with blank entries in at least one of the columns\n",
      "(120, 33)\n"
     ]
    }
   ],
   "source": [
    "print(\"Filtering out points with blank entries in at least one of the columns\")\n",
    "cols = ['PredictedTN','PredictedTP','TEMP','DO','TURB','COND','VEL','SS','WDP','CHLcal','SECCHI']\n",
    "#for col in cols:\n",
    "#    print(col,data[col].isna().sum())\n",
    "qualdata_prediction = filterblanks(cols,data,True)\n",
    "print(qualdata_prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    151.000000\n",
       "mean       0.265133\n",
       "std        0.248787\n",
       "min        0.015000\n",
       "25%        0.167185\n",
       "50%        0.185000\n",
       "75%        0.209663\n",
       "max        1.355000\n",
       "Name: PredictedTP, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"PredictedTP\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    81.000000\n",
       "mean      0.246494\n",
       "std       0.220238\n",
       "min       0.015000\n",
       "25%       0.167000\n",
       "50%       0.185000\n",
       "75%       0.203000\n",
       "max       1.355000\n",
       "Name: TP, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"TP\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    151.000000\n",
       "mean       2.195319\n",
       "std        0.373832\n",
       "min        0.899000\n",
       "25%        2.013365\n",
       "50%        2.282123\n",
       "75%        2.449000\n",
       "max        2.736000\n",
       "Name: PredictedTN, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"PredictedTN\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    81.000000\n",
       "mean      2.214444\n",
       "std       0.411976\n",
       "min       0.899000\n",
       "25%       2.129000\n",
       "50%       2.315000\n",
       "75%       2.477000\n",
       "max       2.736000\n",
       "Name: TN, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"TN\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FLDNUM           0\n",
       "DATE             0\n",
       "PROJCD           0\n",
       "LOCATCD          0\n",
       "WDP              1\n",
       "SECCHI           1\n",
       "SECCHIQF       139\n",
       "STRATUM          0\n",
       "FLDEAST        151\n",
       "FLDNORTH       151\n",
       "TEMP             1\n",
       "TEMPQF         150\n",
       "DO               1\n",
       "DOQF           150\n",
       "TURB             1\n",
       "TURBQF         150\n",
       "COND             1\n",
       "CONDQF         150\n",
       "VEL             31\n",
       "VELQF          120\n",
       "TP              70\n",
       "TPQF            70\n",
       "TN              70\n",
       "TNQF            70\n",
       "SS               1\n",
       "SSQF             1\n",
       "CHLcal           1\n",
       "LATITUDE         0\n",
       "LONGITUDE        0\n",
       "YEAR             0\n",
       "TIME CODE        0\n",
       "PredictedTN      0\n",
       "PredictedTP      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(data, open( \"summer_1997.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = DistanceMatrix(data,\"TN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = matrix.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes\n"
     ]
    }
   ],
   "source": [
    "def transpose(mat, tr, N): \n",
    "    for i in range(N): \n",
    "        for j in range(N): \n",
    "            tr[i][j] = mat[j][i] \n",
    "   \n",
    "# Returns true if mat[N][N] is symmetric, else false \n",
    "def isSymmetric(mat, N): \n",
    "      \n",
    "    tr = [ [0 for j in range(len(mat[0])) ] for i in range(len(mat)) ] \n",
    "    transpose(mat, tr, N) \n",
    "    for i in range(N): \n",
    "        for j in range(N): \n",
    "            if (mat[i][j] != tr[i][j]): \n",
    "                return False\n",
    "    return True\n",
    "   \n",
    "# Driver code \n",
    "if (isSymmetric(array, 151)): \n",
    "    print (\"Yes\")\n",
    "else: \n",
    "    print (\"No\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(151, 151)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.Location'>\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9732061     0.000000\n",
       "9732060     1.097430\n",
       "9732062     1.612008\n",
       "9732008     2.011911\n",
       "9732025     3.130428\n",
       "             ...    \n",
       "9732050    20.539670\n",
       "9732022    20.800828\n",
       "9732064    21.923900\n",
       "9732001    22.458735\n",
       "9732021    25.755405\n",
       "Name: 9732061, Length: 81, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9732060     1.097430\n",
       "9732062     1.612008\n",
       "9732008     2.011911\n",
       "9732025     3.130428\n",
       "9732037     3.286177\n",
       "             ...    \n",
       "9732050    20.539670\n",
       "9732022    20.800828\n",
       "9732064    21.923900\n",
       "9732001    22.458735\n",
       "9732021    25.755405\n",
       "Name: 9732061, Length: 80, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "closest = getclosest(3,matrix,matrix.columns[58])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.075 1.0974304557353052\n",
      "1.7619999999999998 1.612008115880842\n",
      "2.51 2.0119109371293327\n"
     ]
    }
   ],
   "source": [
    "for i,dist in enumerate(closest):\n",
    "    print(closest.index[i].value,dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9732060    1.097430\n",
       "9732062    1.612008\n",
       "9732008    2.011911\n",
       "Name: 9732061, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'Brand' : ['Maruti', 'Hyundai', 'Tata', \n",
    "                                'Mahindra', 'Maruti', 'Hyundai', \n",
    "                                'Renault', 'Tata', 'Maruti'], \n",
    "                     'Year' : [2012, 2014, 2011, 2015, 2012,  \n",
    "                               2016, 2014, 2018, 2019], \n",
    "                     'Kms Driven' : [50000, 30000, 60000,  \n",
    "                                     25000, 10000, 46000,  \n",
    "                                     31000, 15000, 12000], \n",
    "                     'City' : ['Gurgaon', 'Delhi', 'Mumbai',  \n",
    "                               'Delhi', 'Mumbai', 'Delhi',  \n",
    "                               'Mumbai','Chennai',  'Ghaziabad'], \n",
    "                     'Mileage' :  [28, 27, 25, 26, 28,  \n",
    "                                   29, 24, 21, 24]}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    Maruti\n",
       "Name: Brand, dtype: object"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = data.loc[:,\"Brand\"]\n",
    "s[s.index==4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(0,\n",
    "     index=['cobra', 'viper', 'sidewinder'],\n",
    "     columns=['max_speed', 'shield'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_speed</th>\n",
       "      <th>shield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>cobra</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>viper</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sidewinder</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            max_speed  shield\n",
       "cobra               0       0\n",
       "viper               0       0\n",
       "sidewinder          0       0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(1, 5)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"Loc1\":[('LOC1','dist','val'),('LOC2','dist','val')]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest = d[\"Loc1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'loohey'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = 'hey'\n",
    "g = 'loo'\n",
    "g+f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
